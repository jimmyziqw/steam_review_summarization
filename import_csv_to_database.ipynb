{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "024abad3",
   "metadata": {},
   "source": [
    "### import local csv files to aws database for cloud computing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7bd8750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facf9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find csv files in the current working directory\n",
    "def find_csv_files():\n",
    "    csv_files = []\n",
    "    for file in os.listdir(os.getcwd()):\n",
    "        if file.endswith(\".csv\"):\n",
    "            csv_files.append(file)\n",
    "    return csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3ac1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure local directory\n",
    "def configure_dataset_directory(csv_files, dataset_dir):\n",
    "    #create directory\n",
    "    try:#in case folder exists\n",
    "        mkdir = \"mkdir {0}\".format(dataset_dir)\n",
    "        os.system(mkdir)\n",
    "    except:\n",
    "        pass\n",
    "    #move files to directory\n",
    "    for file in csv_files:\n",
    "        move_file =\"mv '{0}' {1}\".format(file, dataset_dir)\n",
    "        os.system(move_file)\n",
    "        #print(move_file)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3f1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(dataset_dir, csv_files):\n",
    "    #path to csv files\n",
    "    data_path = os.getcwd()+\"/\"+dataset_dir+\"/\"\n",
    "    #loop through files and create dataframes\n",
    "    df={}\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df[file] = pd.read_csv(data_path+file)\n",
    "        except UnicodeDecodeError:\n",
    "            df[file] = pd.read_csv(data_path+file, encoding = \"ISO-8859-1\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d2a82d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean table name and column names\n",
    "import string\n",
    "#remove all punctuation except for underscore\n",
    "def remove_punctuation(text):\n",
    "    punctuation_free = \"\".join(i for i in text if i not in string.punctuation)\n",
    "    return punctuation_free\n",
    "def clean_tbl_name(file):\n",
    "    #remove punctuation\n",
    "    file = remove_punctuation(file.lower())\n",
    "    #remove csv\n",
    "    return '{0}'.format(file.split('csv')[0])\n",
    "def clean_col_name(dataframe):\n",
    "    file_df.columns = [remove_punctuation(col_name.lower()) for col_name in file_df.columns]\n",
    "    pd2sql_replacements = {\n",
    "    \"object\": \"varchar\",\n",
    "    \"float64\": \"float\",\n",
    "    \"int64\": \"int\",\n",
    "    \"datetime64\": \"timestamp\",\n",
    "    \"timedelta64[ns]\": \"varchar\"\n",
    "    }\n",
    "    col_str = \",\".join(\"{} {}\".format(n, d) for (n, d) in \\\n",
    "                   zip(file_df.columns, file_df.dtypes.replace(pd2sql_replacements)))\n",
    "    \n",
    "    return col_str, dataframe.columns\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd695bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establish connection to database\n",
    "def connect_to_db(host, dbname, user, password): \n",
    "    try: #default port is 5432\n",
    "        conn = psycopg2.connect(\"host=%s dbname=%s user=%s password=%s\"%(host, dbname, user, password))\n",
    "    except psycopg2.OperationalError as e:\n",
    "        raise e\n",
    "    else:\n",
    "        print('database successfully connected!')\n",
    "        return conn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d16897",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main\n",
    "dataset_dir = \"datasets\"\n",
    "csv_files = find_csv_files()\n",
    "configure_dataset_directory(csv_files, dataset_dir)\n",
    "df = create_df(dataset_dir, csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69297e42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "database successfully connected!\n"
     ]
    }
   ],
   "source": [
    "#database credentials\n",
    "host = \"database-lab.cmv8m35efjhm.us-east-1.rds.amazonaws.com\" \n",
    "dbname = \"postgres\"\n",
    "user=\"postgres\"\n",
    "password = \"XXXXXXX\"\n",
    "#establish a connection to db\n",
    "conn = connect_to_db(host, dbname, user, password)\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5628627",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload csv files to db through loops\n",
    "for file in csv_files:  \n",
    "    file_df = df[file]\n",
    "    #clean table name and column names\n",
    "    tbl_name = clean_tbl_name(file)    \n",
    "    col_str, file_df.columns = clean_col_name(file_df)\n",
    "    #created new table\n",
    "    cursor.execute(\"drop table if exists %s;\"%(tbl_name))\n",
    "    cursor.execute(\"create table %s (%s);\" % (tbl_name, col_str))\n",
    "    print(\"table {0} was created successfully!\".format(tbl_name))\n",
    "    #copy table from csv file\n",
    "    file_df.to_csv(\"%s.csv\" % tbl_name, header = file_df.columns, index=False)\n",
    "    my_file = open(\"%s.csv\" % tbl_name, encoding=\"utf-8\")\n",
    "    #copy \n",
    "    SQL_STATEMENT = \"\"\"\n",
    "        COPY %s from STDIN with\n",
    "        csv\n",
    "        header\n",
    "        delimiter as ','\n",
    "        \"\"\" \n",
    "    cursor.copy_expert(sql=SQL_STATEMENT % (tbl_name), file=my_file)\n",
    "    #grant public access\n",
    "    cursor.execute(\"grant select on table %s to public\" % tbl_name)\n",
    "    conn.commit()\n",
    "    #close connection\n",
    "    cursor.close()\n",
    "    print(\"table {0} imported to db successfully!\".format(tbl_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
