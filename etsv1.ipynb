{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42a3d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9164e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reviews(appid, params={'json':1}):\n",
    "        url = 'https://store.steampowered.com/appreviews/'\n",
    "        response = requests.get(url=url+appid, \n",
    "                                params=params, \n",
    "                                headers=None)\n",
    "        return response.json()\n",
    "\n",
    "    \n",
    "def get_n_reviews(appid, n=100):\n",
    "    reviews = []\n",
    "    #title = None\n",
    "    params = {\n",
    "            'json' : 1,\n",
    "            'filter' : 'recent',\n",
    "            'language' : 'english', \n",
    "            'day_range' : None,\n",
    "            'review_type' : 'all',\n",
    "            'purchase_type' : 'all' \n",
    "            }\n",
    "\n",
    "    cursor = '*'\n",
    "    while n > 0:\n",
    "        params['cursor'] = cursor.encode()\n",
    "       \n",
    "        params['num_per_page'] = min(100, n)\n",
    "        n -= 100\n",
    "        response = get_reviews(appid, params)\n",
    "        cursor = response['cursor']      \n",
    "        reviews += response['reviews']\n",
    "        \n",
    "        if len(response['reviews']) < 100: break\n",
    "   \n",
    "    return reviews\n",
    "def getReviews(appid, reviewNum=1000):\n",
    "    reviews = get_n_reviews(appid, n=reviewNum)\n",
    "    df = pd.DataFrame(columns = [\"review_text\",\"timestamp_created\",\"voted_up\", \"votes_up\", \\\n",
    "                             \"votes_funny\", \"weighted_vote_score\",\"comment_count\"])\n",
    "    for review in reviews:\n",
    "        playtime_at_review = review[\"author\"][\"playtime_at_review\"]\n",
    "        timestamp_created = review[\"timestamp_created\"]\n",
    "        review_text = review[\"review\"]\n",
    "        voted_up = review[\"voted_up\"]\n",
    "        votes_up = review[\"votes_up\"]\n",
    "        votes_funny = review[\"votes_funny\"]\n",
    "        weighted_vote_score = review[\"weighted_vote_score\"]\n",
    "        comment_count = review[\"comment_count\"]\n",
    "\n",
    "        df = df.append({\n",
    "                        \"review_text\":review_text,\n",
    "                        \"timestamp_created\":timestamp_created,\n",
    "                        \"voted_up\":voted_up, \n",
    "                        \"votes_up\":votes_up, \n",
    "                        \"votes_funny\":votes_funny, \n",
    "                        \"weighted_vote_score\": weighted_vote_score,\n",
    "                        \"comment_count\":comment_count,\n",
    "                        },\n",
    "                       ignore_index=True)   \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c839efd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Read the text and tokenize into sentences\n",
    "def read_article(text):\n",
    "    \n",
    "    sentences =[]\n",
    "    \n",
    "    sentences = sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        sentence.replace(\"[^a-zA-Z0-9]\",\" \")\n",
    "\n",
    "    return sentences\n",
    "    \n",
    "\n",
    "# Create vectors and calculate cosine similarity b/w two sentences\n",
    "def sentence_similarity(sent1,sent2,stopwords=None):\n",
    "    if stopwords is None:\n",
    "        stopwords = []\n",
    "    \n",
    "    sent1 = [w.lower() for w in sent1]\n",
    "    sent2 = [w.lower() for w in sent2]\n",
    "    \n",
    "    all_words = list(set(sent1 + sent2))\n",
    "    \n",
    "    vector1 = [0] * len(all_words)\n",
    "    vector2 = [0] * len(all_words)\n",
    "    \n",
    "    #build the vector for the first sentence\n",
    "    for w in sent1:\n",
    "        if not w in stopwords:\n",
    "            vector1[all_words.index(w)]+=1\n",
    "    \n",
    "    #build the vector for the second sentence\n",
    "    for w in sent2:\n",
    "        if not w in stopwords:\n",
    "            vector2[all_words.index(w)]+=1\n",
    "            \n",
    "    return 1-cosine_distance(vector1,vector2)\n",
    "\n",
    "# Create similarity matrix among all sentences\n",
    "def build_similarity_matrix(sentences,stop_words):\n",
    "    #create an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(sentences),len(sentences)))\n",
    "    \n",
    "    for idx1 in range(len(sentences)):\n",
    "        for idx2 in range(len(sentences)):\n",
    "            if idx1!=idx2:\n",
    "                similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1],sentences[idx2],stop_words)\n",
    "                \n",
    "    return similarity_matrix\n",
    "\n",
    "\n",
    "# Generate and return text summary\n",
    "def generate_summary(text,top_n):\n",
    "    #nltk.download('stopwords')\n",
    "    #nltk.download('punkt')\n",
    "    stop_words = stopwords.words('english')\n",
    "    summarize_text = []\n",
    "    \n",
    "    # Step1: read text and tokenize\n",
    "    sentences = read_article(text)\n",
    "    \n",
    "    # Steo2: generate similarity matrix across sentences\n",
    "    sentence_similarity_matrix = build_similarity_matrix(sentences,stop_words)\n",
    "    print()\n",
    "    # Step3: Rank sentences in similarirty matrix\n",
    "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_matrix)\n",
    "    scores = nx.pagerank(sentence_similarity_graph)\n",
    "    \n",
    "    #Step4: sort the rank and place top sentences\n",
    "    ranked_sentences = sorted(((scores[i],s) for i,s in enumerate(sentences)),reverse=True)\n",
    "    \n",
    "    # Step 5: get the top n number of sentences based on rank    \n",
    "    for i in range(top_n):\n",
    "        summarize_text.append(ranked_sentences[i][1])\n",
    "    \n",
    "    # Step 6 : outpur the summarized version\n",
    "    return \" \".join(summarize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcaccc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "appid = \"1145360\"\n",
    "df = getReviews(appid, reviewNum=150)\n",
    "df = df[['review_text','voted_up']]\n",
    "text = df['review_text'].dropna().tolist()\n",
    "text_merge = ' '.join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50506ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wall time: 19.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"And I enjoyed it immensely - so much so that I bought it on Steam after I bought it on the Switch to enjoy better graphics :)\\nThis game completely ruined me for all other roguelikes - I have been searching for similar games, but there are none. dad bad\\ndoggo goodie yup, played a good game before you can pet 3 headed dogo enemies go brr God game You can't hade this game i like this game but the green bow lady makes my fairly oddparents underwear wet This game is excellent in more than one way: Art, storytelling, comedy, combat, repeatability and difficulty. The amount of dialogue and story they fit into a ROGUE-LIKE game is incredible.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "generate_summary(text_merge,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c598546",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
